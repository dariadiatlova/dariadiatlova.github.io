---
layout: default
title: EmoSpeech: guiding FastSpeech2 towards Emotional Text to Speech
description: State-of-the-art speech synthesis models try to get as close as possible to the human voice. Hence, modelling emotions is an essential part of Text-To-Speech (TTS) research. In our work, we selected FastSpeech2 as the starting point and proposed a series of modifications for synthesizing emotional speech. Ac- cording to automatic and human evaluation, our model, Emo- Speech, surpasses existing models regarding both MOS score and emotion recognition accuracy in generated speech. We provided a detailed ablation study for every extension to Fast- Speech2 architecture that forms EmoSpeech. The uneven dis- tribution of emotions in the text is crucial for better, synthe- sized speech and intonation perception. Our model includes a conditioning mechanism that effectively handles this issue by allowing emotions to contribute to each phone with varying in- tensity levels. The human assessment indicates that proposed modifications generate audio with higher MOS and emotional expressiveness.
---
[Paper](https://openreview.net/pdf?id=LYgrzXwVsm) [Code](https://github.com/deepvk/emospeech)